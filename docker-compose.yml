services:
  streamlit:
    build: .
    #image: registry.gitlab.com/kondziuu03/rag-llm
    ports:
      - "8501:8501"
    volumes:
      - data:/app/data
      - chroma:/app/chroma
      - ~/.cache/huggingface:/root/.cache/huggingface
    depends_on:
      - ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: ["gpu"]
  ollama:
    container_name: ollama-service
    image: ollama/ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: ["gpu"]

  ollama-watchdog:
    image: docker
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    command: >
      sh -c "while true; do
             sleep 10800;
             docker restart ollama-service;
             done"
    depends_on:
      - ollama
volumes:
  ollama:
  data:
  chroma:
  hugs_cache: